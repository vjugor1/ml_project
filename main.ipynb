{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fc0zv2vkhJRL"
   },
   "outputs": [],
   "source": [
    "#HYPER-PARAMETERS\n",
    "k           = 7\n",
    "DIMR        = 250\n",
    "PCA_flag    = False\n",
    "LCN_flag    = False\n",
    "num_epoch   = 270\n",
    "num_hid     = DIMR\n",
    "batch_sz    = 1000\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from IPython import display\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torchvision\n",
    "from tqdm import trange\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "FjaHDBM3hJRX",
    "outputId": "2df2fc68-cbc5-426d-c4d1-318b8bf638f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "total trainning batch number: 48\n",
      "total val batch number: 12\n",
      "total testing batch number: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ', device)\n",
    "# set_random_seeds(seed_value=0, device=device)\n",
    "\n",
    "\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "#validation split\n",
    "split_coeff = 0.2\n",
    "train_sampler = SubsetRandomSampler(range(int(split_coeff*len(train_set)), len(train_set)))\n",
    "valid_sampler = SubsetRandomSampler(range(int(split_coeff*len(train_set))))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_sz,\n",
    "                 sampler=valid_sampler)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_sz,\n",
    "                 sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_sz,\n",
    "                shuffle=False)\n",
    "\n",
    "print('total trainning batch number: {}'.format(len(train_loader)))\n",
    "print('total val batch number: {}'.format(len(val_loader)))\n",
    "print('total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1P-PNzCMhJRk",
    "outputId": "d456771b-4be3-464c-9c6a-2f3f11b83313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_side:  28\n"
     ]
    }
   ],
   "source": [
    "img_side = np.array(train_set[0][0]).shape[1]\n",
    "print('img_side: ',img_side  )\n",
    "num_classes = 10 #for mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deHAxXEHhJRs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3c92m_e3hJR4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class cccml(nn.Module):\n",
    "    def __init__ (self, dim_reduce, img_side,  num_classes, batch_size, num_channels=1, nkerns=[10,10], poolsize=(2, 2), f0 = 5, f1 = 3):\n",
    "        super().__init__()\n",
    "#         self.D =  int(np.sqrt(num_dims / num_channels))\n",
    "        self.D = img_side\n",
    "        self.batch_size = batch_size\n",
    "        self.dim_reduce = dim_reduce\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        \n",
    "        numpy_rng=np.random.RandomState(1234)\n",
    "        \n",
    "        self.image_shape0=[batch_size, num_channels, self.D, self.D]\n",
    "        self.filter_shape0=(nkerns[0], num_channels, f0, f0) #TODO \n",
    "        img_out_size0= (self.D-f0+1)/poolsize[0]\n",
    "        \n",
    "        self.image_shape1=[batch_size, nkerns[0], img_out_size0, img_out_size0]\n",
    "        self.filter_shape1=(nkerns[1], nkerns[0], f1, f1) #TODO \n",
    "        img_out_size1= (img_out_size0-f1+1)/poolsize[0]\n",
    "        print('Layer0: Filter size %d, image size out %d' % (f0, img_out_size0))\n",
    "        print('Layer1: Filter size %d, image size out %d' % (f1, img_out_size1))\n",
    "       \n",
    "        convL1_dim = img_out_size1\n",
    "        num_convH = nkerns[-1]*convL1_dim*convL1_dim\n",
    "        print(num_convH)\n",
    "        print(convL1_dim)\n",
    "        \n",
    "        \n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channels, out_channels=10, kernel_size=f0),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            nn.Tanh())\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=100, kernel_size=f1),\n",
    "            nn.BatchNorm2d(100),\n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            nn.Tanh())\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2500, self.dim_reduce, bias=False))\n",
    "\n",
    "        \n",
    "    def forward(self, X, num_train=None):\n",
    "        X = self.stage1(X)\n",
    "        X = self.stage2(X)\n",
    "#         print(np.array(X).shape)\n",
    "        X = self.fc(X.view(-1, 2500))\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UVhrwLZhJRz"
   },
   "outputs": [],
   "source": [
    "k_near = 2\n",
    "p_metr = 2\n",
    "\n",
    "class CKNN_loss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "           \n",
    "    @staticmethod\n",
    "    def get_priors(inp, target):\n",
    "        priors = {}\n",
    "        n = target.size()[0]\n",
    "        d = {x: list(target.cpu().numpy()).count(x) for x in target.cpu().numpy()}\n",
    "#         a, b = d.keys(), d.values()\n",
    "        for i in range(len(d.keys())):\n",
    "            priors[str(torch.tensor(list(d.keys())[i]))] = torch.tensor(np.float64(list(d.values())[i]), requires_grad=True)\n",
    "        return priors\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_distances(inp, target):\n",
    "        dist_dict = {}\n",
    "        for t in torch.unique(target):\n",
    "            dist_dict[str(t)] = []\n",
    "        for t in torch.unique(target):\n",
    "            for i in torch.arange(len(target)):\n",
    "                if target[i].cpu().numpy() == t.cpu().numpy():\n",
    "                    dist_dict[str(t)].append(torch.norm(inp[-1][0] - inp[i][0], p=p_metr))\n",
    "        for t in torch.unique(target):\n",
    "            #print(dist_dict[str(t)], 123231)\n",
    "            dist_dict[str(t)] = torch.tensor(dist_dict[str(t)], requires_grad=True)\n",
    "            #print(dist_dict[str(t)])\n",
    "            dist_dict[str(t)] = dist_dict[str(t)].topk(k=k_near, largest=False)[0]\n",
    "        return dist_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sigma(dist_dict):\n",
    "        return torch.std(torch.flatten(torch.stack(list(dist_dict.values()))))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_likelihood(near_dict_dist, sigma):\n",
    "        likelihood_dict = {}\n",
    "        for key in near_dict_dist.keys():\n",
    "            curr_list = near_dict_dist[key]\n",
    "            likelihood_dict[key] = torch.exp(-torch.sum(curr_list**2) / sigma)\n",
    "        return likelihood_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def get_posteriors(priors, likelihoods):\n",
    "        #print(priors.keys())\n",
    "        posteriors  = {key: priors[str(key)] * likelihoods[str(key)] for key in priors.keys()}\n",
    "        return posteriors\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_term_of_loss(inp, target, i):\n",
    "        priors     = CKNN_loss.get_priors(inp, target)\n",
    "        distances  = CKNN_loss.get_distances(inp, target)\n",
    "        sigma      = CKNN_loss.get_sigma(distances)\n",
    "        likelih    = CKNN_loss.get_likelihood(distances, sigma)\n",
    "        posteriors = CKNN_loss.get_posteriors(priors, likelih)\n",
    "        return -posteriors[str(target[i])]\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(inp, target):\n",
    "#         print(target.size())\n",
    "        res = torch.tensor(0.)\n",
    "#         for i in torch.arange(target.size()[0]):\n",
    "        for i in torch.arange(torch.tensor(10)):\n",
    "\n",
    "            inp1 = torch.cat((torch.index_select(inp, 1, Variable(torch.LongTensor(list(range(i)) + list(range(i+1, DIMR))))),\n",
    "                              torch.index_select(inp, 1, Variable(torch.LongTensor([i])))), dim=1)\n",
    "            target1 = torch.index_select(target, 0, Variable(torch.LongTensor(list(range(i)) + list(range(i+1, batch_sz)))))\n",
    "\n",
    "\n",
    "            torch.add(res, CKNN_loss.get_term_of_loss(inp, target, target[i]))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PnCOk9o6hJR-"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from tqdm import trange\n",
    "import os\n",
    "def get_score(model, dataloader, device='cpu'):\n",
    "    ac = CKNN_loss()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)  \n",
    "            y = y.to(device)  \n",
    "            dataloader_neg_posterior += ac(x, y)\n",
    "    return dataloader_neg_posterior/len(dataloader)\n",
    "def train(model, optimizer, criterion, train_loader, val_loader,device, epochs_n=100):  \n",
    "    model.to(device)\n",
    "\n",
    "    learning_curve = [np.nan] * epochs_n\n",
    "    train_accuracy_curve = [np.nan] * epochs_n\n",
    "    val_accuracy_curve = [np.nan] * epochs_n\n",
    "    max_val_accuracy = 0\n",
    "    max_val_accuracy_epoch = 0\n",
    "    train_size = len(train_loader)\n",
    "    batch_size=16\n",
    "    batches_n = (train_size - 1) // batch_size + 1\n",
    "\n",
    "    for epoch in range(epochs_n):\n",
    "        model.train()\n",
    "\n",
    "        learning_curve[epoch] = 0\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(x).requires_grad_(True)\n",
    "            \n",
    "            loss = criterion(prediction, y)\n",
    "            loss = Variable(loss, requires_grad = True)\n",
    "            learning_curve[epoch] += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(loss.item())\n",
    "            print(i)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        f, axes = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "        learning_curve[epoch] /= batches_n\n",
    "        axes[0].plot(learning_curve)\n",
    "\n",
    "        model.eval()\n",
    "        train_accuracy_curve[epoch] = get_accuracy(model, train_loader, device)\n",
    "        val_accuracy_curve[epoch] = get_accuracy(model, val_loader, device)\n",
    "        \n",
    "        val_accuracy = val_accuracy_curve[epoch]\n",
    "        if val_accuracy > max_val_accuracy:\n",
    "            max_val_accuracy = val_accuracy\n",
    "            max_val_accuracy_epoch = epoch\n",
    "            model_dir = os.getcwd()+\"/best_model\"\n",
    "            torch.save(model, model_dir)\n",
    "        \n",
    "        axes[1].set_title('Train {:.4f}, val {:.4f}, max val {:.4f} at {}'.format(\n",
    "            train_accuracy_curve[epoch], val_accuracy, max_val_accuracy, max_val_accuracy_epoch))\n",
    "        axes[1].plot(train_accuracy_curve)\n",
    "        axes[1].plot(val_accuracy_curve)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "7b8M_TwkhJSG",
    "outputId": "625a1f94-72b3-4a70-cecd-bfb3b9efd553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer0: Filter size 5, image size out 12\n",
      "Layer1: Filter size 3, image size out 5\n",
      "250.0\n",
      "5.0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [1000, 10, 24, 24]             260\n",
      "       BatchNorm2d-2         [1000, 10, 24, 24]              20\n",
      "         MaxPool2d-3         [1000, 10, 12, 12]               0\n",
      "              Tanh-4         [1000, 10, 12, 12]               0\n",
      "            Conv2d-5        [1000, 100, 10, 10]           9,100\n",
      "       BatchNorm2d-6        [1000, 100, 10, 10]             200\n",
      "         MaxPool2d-7          [1000, 100, 5, 5]               0\n",
      "              Tanh-8          [1000, 100, 5, 5]               0\n",
      "            Linear-9                [1000, 250]         625,000\n",
      "================================================================\n",
      "Total params: 634,580\n",
      "Trainable params: 634,580\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.99\n",
      "Forward/backward pass size (MB): 302.51\n",
      "Params size (MB): 2.42\n",
      "Estimated Total Size (MB): 307.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = cccml(dim_reduce=num_hid, img_side=img_side, num_classes=num_classes, batch_size=batch_sz).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),  lr=0.005, momentum=0.9)\n",
    "criterion = CKNN_loss() ##\n",
    "#         knn = KNN()\n",
    "# hyper_params=[num_dims, num_train_cases, num_test_cases, num_hid, num_classes, \\\n",
    "#                 num_epoch, epsilon, batch_sz, k, model_type, weightcost]\n",
    "#         knn_acc, cknn_acc, acc3, acc4 = run(train_set, valid_set, test_set, knn, hyper_params)\n",
    "#         save.append([knn_acc, cknn_acc, acc3, acc4])\n",
    "summary(model, (1, 28, 28), batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1583
    },
    "colab_type": "code",
    "id": "vo7jTuKuhJSL",
    "outputId": "6722848e-6bce-4054-b7a4-328db8e09852"
   },
   "outputs": [],
   "source": [
    "train(model, optimizer, criterion, train_loader, val_loader,device=device, epochs_n=100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "maine.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
